{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, import libraries needed to run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "#import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have a glance of the list of files stored in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fnc.csv',\n",
       " 'loading.csv',\n",
       " 'ICN_numbers.csv',\n",
       " 'trends_neuroimaging-master',\n",
       " 'sample_submission.csv',\n",
       " '10003.mat.zip',\n",
       " 'train_scores.csv',\n",
       " '10001.mat.zip',\n",
       " 'reveal_ID_site2.csv',\n",
       " 'fMRI_mask.nii']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read into the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = pd.read_csv(\"data/train_scores.csv\")\n",
    "fnc = pd.read_csv(\"data/fnc.csv\")\n",
    "loading = pd.read_csv(\"data/loading.csv\")\n",
    "icn_no = pd.read_csv(\"data/ICN_numbers.csv\")\n",
    "id_site2 = pd.read_csv(\"data/reveal_ID_site2.csv\")\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just keeping a note of the no. of columns/variables in each file\n",
    "length of train_scores.columns (inclu. id): 6  \n",
    "length of loading.columns (inclu. id) : 27  \n",
    "length of fnc.columns (inclu. id) : 1379\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with missing data\n",
    "There are missing values in the 'train_scores.csv' file (i.e. in some of the 'domain_' variables). \n",
    "Depending on your strategy, the missing data need to be treated. Here, we just substitute the missing data with mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_scores.isnull().sum()\n",
    "train_scores.fillna(train_scores.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, combine and restrict to only train_data (the 'train_scores.csv' file contains only ID for 'train' cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "      <th>IC_01</th>\n",
       "      <th>IC_07</th>\n",
       "      <th>IC_05</th>\n",
       "      <th>IC_16</th>\n",
       "      <th>...</th>\n",
       "      <th>CBN(13)_vs_DMN(94)</th>\n",
       "      <th>CBN(18)_vs_DMN(94)</th>\n",
       "      <th>CBN(4)_vs_DMN(94)</th>\n",
       "      <th>CBN(7)_vs_DMN(94)</th>\n",
       "      <th>CBN(18)_vs_CBN(13)</th>\n",
       "      <th>CBN(4)_vs_CBN(13)</th>\n",
       "      <th>CBN(7)_vs_CBN(13)</th>\n",
       "      <th>CBN(4)_vs_CBN(18)</th>\n",
       "      <th>CBN(7)_vs_CBN(18)</th>\n",
       "      <th>CBN(7)_vs_CBN(4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.014466</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.971166e-07</td>\n",
       "      <td>2.211365e-06</td>\n",
       "      <td>5.241842e-07</td>\n",
       "      <td>1.341784e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-1.714134e-07</td>\n",
       "      <td>4.985075e-07</td>\n",
       "      <td>-2.428485e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.161953e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "      <td>0.009087</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>-0.002076</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.568648e-07</td>\n",
       "      <td>-1.591679e-07</td>\n",
       "      <td>5.720555e-07</td>\n",
       "      <td>-7.598477e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.776925e-06</td>\n",
       "      <td>2.369750e-06</td>\n",
       "      <td>1.145950e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.933081e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.213564e-07</td>\n",
       "      <td>1.238158e-06</td>\n",
       "      <td>5.658740e-07</td>\n",
       "      <td>1.234127e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>8.563871e-07</td>\n",
       "      <td>1.270224e-06</td>\n",
       "      <td>4.974028e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.254311e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>51.474692</td>\n",
       "      <td>59.244132</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.580981e-07</td>\n",
       "      <td>1.579727e-06</td>\n",
       "      <td>1.617702e-07</td>\n",
       "      <td>1.713334e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.067021e-06</td>\n",
       "      <td>9.095169e-07</td>\n",
       "      <td>1.159346e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.515938e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.008716e-07</td>\n",
       "      <td>1.635702e-06</td>\n",
       "      <td>2.880146e-07</td>\n",
       "      <td>6.303288e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.421790e-06</td>\n",
       "      <td>1.850702e-06</td>\n",
       "      <td>6.440192e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.174430e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2  \\\n",
       "0  10001  57.436077     30.571975     62.553736     53.325130     51.427998   \n",
       "1  10002  59.580851     50.969456     67.470628     60.651856     58.311361   \n",
       "2  10004  71.413018     53.152498     58.012103     52.418389     62.536641   \n",
       "3  10005  66.532630     51.474692     59.244132     52.108977     69.993075   \n",
       "4  10007  38.617381     49.197021     65.674285     40.151376     34.096421   \n",
       "\n",
       "      IC_01     IC_07     IC_05     IC_16  ...  CBN(13)_vs_DMN(94)  \\\n",
       "0  0.006070  0.014466  0.004136  0.000658  ...       -5.971166e-07   \n",
       "1  0.009087  0.009291  0.007049 -0.002076  ...       -8.568648e-07   \n",
       "2  0.004675  0.000957  0.006154 -0.000429  ...       -5.213564e-07   \n",
       "3 -0.000398  0.006878  0.009051  0.000369  ...       -5.580981e-07   \n",
       "4  0.005192  0.010585  0.012160 -0.000920  ...       -6.008716e-07   \n",
       "\n",
       "   CBN(18)_vs_DMN(94)  CBN(4)_vs_DMN(94)  CBN(7)_vs_DMN(94)  \\\n",
       "0        2.211365e-06       5.241842e-07       1.341784e-06   \n",
       "1       -1.591679e-07       5.720555e-07      -7.598477e-07   \n",
       "2        1.238158e-06       5.658740e-07       1.234127e-07   \n",
       "3        1.579727e-06       1.617702e-07       1.713334e-06   \n",
       "4        1.635702e-06       2.880146e-07       6.303288e-07   \n",
       "\n",
       "   CBN(18)_vs_CBN(13)  CBN(4)_vs_CBN(13)  CBN(7)_vs_CBN(13)  \\\n",
       "0            0.000002      -1.714134e-07       4.985075e-07   \n",
       "1            0.000002       1.776925e-06       2.369750e-06   \n",
       "2            0.000001       8.563871e-07       1.270224e-06   \n",
       "3            0.000002       1.067021e-06       9.095169e-07   \n",
       "4            0.000002       1.421790e-06       1.850702e-06   \n",
       "\n",
       "   CBN(4)_vs_CBN(18)  CBN(7)_vs_CBN(18)  CBN(7)_vs_CBN(4)  \n",
       "0      -2.428485e-07           0.000002      1.161953e-06  \n",
       "1       1.145950e-07           0.000003      9.933081e-07  \n",
       "2       4.974028e-08           0.000003      3.254311e-07  \n",
       "3       1.159346e-07           0.000003      3.515938e-07  \n",
       "4       6.440192e-07           0.000003      1.174430e-06  \n",
       "\n",
       "[5 rows x 1410 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are a lot of features in the fnc file. 'Rescale' them to prevent potential overfitting\n",
    "FNC_SCALE = 1/500\n",
    "fnc_features = fnc.columns[1:]\n",
    "fnc[fnc_features] *= FNC_SCALE\n",
    "\n",
    "\n",
    "train_data = train_scores.merge(loading, on='Id', how='left')\n",
    "train_data = train_data.merge(fnc, on='Id', how='left')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Threshold FS Attempt #not too helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "#X_train_clone = X_train.copy()\n",
    "#selector=VarianceThreshold()\n",
    "#X_train_new = selector.fit_transform(X_train_clone)\n",
    "#\n",
    "#X_train_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try PCA for data reduction\n",
    "##### on loading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18168026 0.15362637 0.13054658 0.0755652  0.06002084]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "loading_feat = loading.drop('Id', axis=1)\n",
    "\n",
    "load_pca5 = PCA(n_components = 5)\n",
    "load_pca5_sco = load_pca5.fit_transform(loading_feat)\n",
    "\n",
    "print(load_pca5.explained_variance_ratio_)\n",
    "\n",
    "load_pca_df = pd.DataFrame(data = load_pca5_sco, columns = ['loadpc1', 'loadpc2', 'loadpc3', 'loadpc4', 'loadpc5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>loadpc1</th>\n",
       "      <th>loadpc2</th>\n",
       "      <th>loadpc3</th>\n",
       "      <th>loadpc4</th>\n",
       "      <th>loadpc5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>-0.009915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>-0.004325</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.008553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>0.024332</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>-0.009372</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>-0.014058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.005532</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>-0.009241</td>\n",
       "      <td>0.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>-0.006259</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>-0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11749</th>\n",
       "      <td>21750</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>-0.003347</td>\n",
       "      <td>-0.005168</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11750</th>\n",
       "      <td>21751</td>\n",
       "      <td>-0.008887</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>-0.005971</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>0.001193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11751</th>\n",
       "      <td>21752</td>\n",
       "      <td>-0.011322</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.002126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11752</th>\n",
       "      <td>21753</td>\n",
       "      <td>-0.002964</td>\n",
       "      <td>-0.008021</td>\n",
       "      <td>-0.024727</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>-0.019007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11753</th>\n",
       "      <td>21754</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>-0.011327</td>\n",
       "      <td>0.012856</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>-0.006648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11754 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id   loadpc1   loadpc2   loadpc3   loadpc4   loadpc5\n",
       "0      10001  0.008631  0.005304  0.010155  0.011989 -0.009915\n",
       "1      10002  0.002058 -0.004325  0.006301  0.005274 -0.008553\n",
       "2      10003  0.024332  0.008228 -0.009372  0.008338 -0.014058\n",
       "3      10004 -0.000176 -0.005532  0.006451 -0.009241  0.003857\n",
       "4      10005 -0.006259 -0.002157  0.016069 -0.000303 -0.000221\n",
       "...      ...       ...       ...       ...       ...       ...\n",
       "11749  21750  0.011279  0.009309 -0.003347 -0.005168  0.002109\n",
       "11750  21751 -0.008887  0.008090 -0.005971 -0.001368  0.001193\n",
       "11751  21752 -0.011322  0.008178  0.013650 -0.000309 -0.002126\n",
       "11752  21753 -0.002964 -0.008021 -0.024727  0.002965 -0.019007\n",
       "11753  21754  0.001936 -0.011327  0.012856  0.004066 -0.006648\n",
       "\n",
       "[11754 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pca_df = pd.concat([loading[['Id']], load_pca_df], axis=1)\n",
    "load_pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also tried n_components = 8 or 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load_pca7 = PCA(n_components = 8)\n",
    "#load_pca7_sco = load_pca7.fit_transform(loading_feat)\n",
    "#\n",
    "#load_pca7.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### on fnc features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13839599 0.03939586 0.0355435  0.0310792  0.02873212]\n"
     ]
    }
   ],
   "source": [
    "fnc2 = pd.read_csv(\"data/fnc.csv\")\n",
    "fnc2\n",
    "\n",
    "fnc2_feat = fnc2.drop('Id', axis=1)\n",
    "\n",
    "fnc2_pca5 = PCA(n_components = 5)\n",
    "fnc2_pca5_sco = fnc2_pca5.fit_transform(fnc2_feat)\n",
    "\n",
    "print(fnc2_pca5.explained_variance_ratio_)\n",
    "\n",
    "fnc2_pca_df = pd.DataFrame(data = fnc2_pca5_sco, columns = ['fncpc1', 'fncpc2', 'fncpc3', 'fncpc4', 'fncpc5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>fncpc1</th>\n",
       "      <th>fncpc2</th>\n",
       "      <th>fncpc3</th>\n",
       "      <th>fncpc4</th>\n",
       "      <th>fncpc5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>-1.961551</td>\n",
       "      <td>-0.485216</td>\n",
       "      <td>-0.670196</td>\n",
       "      <td>1.212302</td>\n",
       "      <td>0.409607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>-1.448180</td>\n",
       "      <td>-0.842196</td>\n",
       "      <td>1.347581</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>-0.676815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>2.171379</td>\n",
       "      <td>2.326829</td>\n",
       "      <td>0.225485</td>\n",
       "      <td>-0.331557</td>\n",
       "      <td>-0.357406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>-1.329180</td>\n",
       "      <td>-1.249633</td>\n",
       "      <td>-1.083624</td>\n",
       "      <td>0.503536</td>\n",
       "      <td>0.342165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>-0.529954</td>\n",
       "      <td>-1.398175</td>\n",
       "      <td>0.681247</td>\n",
       "      <td>-1.683166</td>\n",
       "      <td>-0.303521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11749</th>\n",
       "      <td>21750</td>\n",
       "      <td>-2.350324</td>\n",
       "      <td>1.647932</td>\n",
       "      <td>-0.927377</td>\n",
       "      <td>0.118520</td>\n",
       "      <td>1.560186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11750</th>\n",
       "      <td>21751</td>\n",
       "      <td>-2.329617</td>\n",
       "      <td>1.181409</td>\n",
       "      <td>0.938004</td>\n",
       "      <td>0.491912</td>\n",
       "      <td>-1.280158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11751</th>\n",
       "      <td>21752</td>\n",
       "      <td>0.510884</td>\n",
       "      <td>-0.057311</td>\n",
       "      <td>0.287507</td>\n",
       "      <td>-0.521226</td>\n",
       "      <td>0.757112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11752</th>\n",
       "      <td>21753</td>\n",
       "      <td>-1.011531</td>\n",
       "      <td>0.018133</td>\n",
       "      <td>1.721649</td>\n",
       "      <td>0.170403</td>\n",
       "      <td>-0.582430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11753</th>\n",
       "      <td>21754</td>\n",
       "      <td>-2.432370</td>\n",
       "      <td>2.732441</td>\n",
       "      <td>-0.782331</td>\n",
       "      <td>0.439348</td>\n",
       "      <td>0.930193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11754 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id    fncpc1    fncpc2    fncpc3    fncpc4    fncpc5\n",
       "0      10001 -1.961551 -0.485216 -0.670196  1.212302  0.409607\n",
       "1      10002 -1.448180 -0.842196  1.347581  0.998600 -0.676815\n",
       "2      10003  2.171379  2.326829  0.225485 -0.331557 -0.357406\n",
       "3      10004 -1.329180 -1.249633 -1.083624  0.503536  0.342165\n",
       "4      10005 -0.529954 -1.398175  0.681247 -1.683166 -0.303521\n",
       "...      ...       ...       ...       ...       ...       ...\n",
       "11749  21750 -2.350324  1.647932 -0.927377  0.118520  1.560186\n",
       "11750  21751 -2.329617  1.181409  0.938004  0.491912 -1.280158\n",
       "11751  21752  0.510884 -0.057311  0.287507 -0.521226  0.757112\n",
       "11752  21753 -1.011531  0.018133  1.721649  0.170403 -0.582430\n",
       "11753  21754 -2.432370  2.732441 -0.782331  0.439348  0.930193\n",
       "\n",
       "[11754 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnc2_pca_df = pd.concat([fnc2[['Id']], fnc2_pca_df], axis=1)\n",
    "fnc2_pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also tried n_components = 8 or 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fnc2_pca10 = PCA(n_components = 10)\n",
    "#fnc2_pca10_sco = fnc2_pca10.fit_transform(fnc2_feat)\n",
    "#\n",
    "#print(fnc2_pca10.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining pca-ed feature train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>domain1_var1</th>\n",
       "      <th>domain1_var2</th>\n",
       "      <th>domain2_var1</th>\n",
       "      <th>domain2_var2</th>\n",
       "      <th>loadpc1</th>\n",
       "      <th>loadpc2</th>\n",
       "      <th>loadpc3</th>\n",
       "      <th>loadpc4</th>\n",
       "      <th>loadpc5</th>\n",
       "      <th>fncpc1</th>\n",
       "      <th>fncpc2</th>\n",
       "      <th>fncpc3</th>\n",
       "      <th>fncpc4</th>\n",
       "      <th>fncpc5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>57.436077</td>\n",
       "      <td>30.571975</td>\n",
       "      <td>62.553736</td>\n",
       "      <td>53.325130</td>\n",
       "      <td>51.427998</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>-0.009915</td>\n",
       "      <td>-1.961551</td>\n",
       "      <td>-0.485216</td>\n",
       "      <td>-0.670196</td>\n",
       "      <td>1.212302</td>\n",
       "      <td>0.409607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>59.580851</td>\n",
       "      <td>50.969456</td>\n",
       "      <td>67.470628</td>\n",
       "      <td>60.651856</td>\n",
       "      <td>58.311361</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>-0.004325</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.008553</td>\n",
       "      <td>-1.448180</td>\n",
       "      <td>-0.842196</td>\n",
       "      <td>1.347581</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>-0.676815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>71.413018</td>\n",
       "      <td>53.152498</td>\n",
       "      <td>58.012103</td>\n",
       "      <td>52.418389</td>\n",
       "      <td>62.536641</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.005532</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>-0.009241</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>-1.329180</td>\n",
       "      <td>-1.249633</td>\n",
       "      <td>-1.083624</td>\n",
       "      <td>0.503536</td>\n",
       "      <td>0.342165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>66.532630</td>\n",
       "      <td>51.474692</td>\n",
       "      <td>59.244132</td>\n",
       "      <td>52.108977</td>\n",
       "      <td>69.993075</td>\n",
       "      <td>-0.006259</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>-0.529954</td>\n",
       "      <td>-1.398175</td>\n",
       "      <td>0.681247</td>\n",
       "      <td>-1.683166</td>\n",
       "      <td>-0.303521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>38.617381</td>\n",
       "      <td>49.197021</td>\n",
       "      <td>65.674285</td>\n",
       "      <td>40.151376</td>\n",
       "      <td>34.096421</td>\n",
       "      <td>-0.004811</td>\n",
       "      <td>-0.003609</td>\n",
       "      <td>-0.005884</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>-0.021605</td>\n",
       "      <td>-0.985573</td>\n",
       "      <td>2.629944</td>\n",
       "      <td>-1.358889</td>\n",
       "      <td>0.961028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        age  domain1_var1  domain1_var2  domain2_var1  domain2_var2  \\\n",
       "0  10001  57.436077     30.571975     62.553736     53.325130     51.427998   \n",
       "1  10002  59.580851     50.969456     67.470628     60.651856     58.311361   \n",
       "2  10004  71.413018     53.152498     58.012103     52.418389     62.536641   \n",
       "3  10005  66.532630     51.474692     59.244132     52.108977     69.993075   \n",
       "4  10007  38.617381     49.197021     65.674285     40.151376     34.096421   \n",
       "\n",
       "    loadpc1   loadpc2   loadpc3   loadpc4   loadpc5    fncpc1    fncpc2  \\\n",
       "0  0.008631  0.005304  0.010155  0.011989 -0.009915 -1.961551 -0.485216   \n",
       "1  0.002058 -0.004325  0.006301  0.005274 -0.008553 -1.448180 -0.842196   \n",
       "2 -0.000176 -0.005532  0.006451 -0.009241  0.003857 -1.329180 -1.249633   \n",
       "3 -0.006259 -0.002157  0.016069 -0.000303 -0.000221 -0.529954 -1.398175   \n",
       "4 -0.004811 -0.003609 -0.005884  0.001857  0.001724 -0.021605 -0.985573   \n",
       "\n",
       "     fncpc3    fncpc4    fncpc5  \n",
       "0 -0.670196  1.212302  0.409607  \n",
       "1  1.347581  0.998600 -0.676815  \n",
       "2 -1.083624  0.503536  0.342165  \n",
       "3  0.681247 -1.683166 -0.303521  \n",
       "4  2.629944 -1.358889  0.961028  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train_data = train_scores.merge(load_pca_df, on='Id', how='left')\n",
    "pca_train_data = pca_train_data.merge(fnc2_pca_df, on='Id', how='left')\n",
    "pca_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into X_train, y_train for train data, and only X_test for test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')\n",
    "\n",
    "#prepare the train data (X_train: features; y_train: outcomes)\n",
    "Xpca_train = pca_train_data.drop(list(targets), axis=1).drop('Id', axis=1)\n",
    "ypca_train = pca_train_data[list(targets)]\n",
    "\n",
    "## prepare the test data\n",
    "## Here, the 'fnc' features have already been 'rescaled' with a multiplication of 1/500\n",
    "#Id_no = submission['Id'].apply(lambda x: int(x.split('_')[0])).unique()\n",
    "#test = pd.DataFrame({'Id' : Id_no})\n",
    "#test_pred_df = test.copy()\n",
    "##submission.head()\n",
    "#test_data = test.merge(loading, on='Id', how='left')\n",
    "#test_data = test_data.merge(fnc, on='Id', how='left')\n",
    "#\n",
    "#X_test = test_data.drop('Id', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cross_val_predict to train/test model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict #, #GridSearchCV, KFold, \n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(random_state = 29, \n",
    "                      n_estimators=20\n",
    "                             )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.1750480103248077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain1_var1: 0.15128620496999926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain1_var2: 0.14825131714917636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain2_var1: 0.19001609942364484\n",
      "domain2_var2: 0.1853737764169167\n",
      "Overall-score: 0.17062669774039632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.3s finished\n"
     ]
    }
   ],
   "source": [
    "#To do cross_val_predict here\n",
    "\n",
    "def eval_metric(y_true, y_pred):\n",
    "    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))\n",
    "\n",
    "\n",
    "weights = (.3, .175, .175, .175, .175)\n",
    "target_scores = []\n",
    "\n",
    "overall_score=0\n",
    "\n",
    "for col, weight in zip(targets, weights): \n",
    "    ypca_pred_train = cross_val_predict(model, Xpca_train, ypca_train[col], cv=5, n_jobs=-1, verbose=2)\n",
    "    \n",
    "    #print(y_pred_train)\n",
    "    \n",
    "    score = eval_metric(ypca_train[col], ypca_pred_train)\n",
    "    overall_score += score*weight\n",
    "    \n",
    "    target_scores.append((col, score))\n",
    "    print(\"{}: {}\".format(col,score))\n",
    "\n",
    "target_scores.append(('overall-score', overall_score))\n",
    "print(\"Overall-score: {}\".format(overall_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model.__class__.__name__\n",
    "#report.write(\"---\" + model_name +  \"---\" +\"\\n\")\n",
    "\n",
    "\n",
    "report = open('try_pca_outfile.txt', 'w')\n",
    "\n",
    "report.write(\"---\" + model_name +  \"---\" +\"\\n\")\n",
    "report.write(str(model.get_params()))\n",
    "\n",
    "\n",
    "#report.write(\"-\" * 45 + '\\n')get\n",
    "#report.write(\"!train feature data are pca scores from loading & fnc seperately (5pcs in each case!)\" + \"\\n\")\n",
    "#report.write(\"---gridsearch: \" + \"-\"*30 + \"\\n\")\n",
    "#report.write(str(gs) + \"\\n\" + \"\\n\")\n",
    "\n",
    "#report.write(\"---best model params for each target :\" + \"-\"*20 +\"\\n\")\n",
    "#report.write(str(best_models10) + \"\\n\" +\"\\n\")\n",
    "\n",
    "#report.write(\"---model CV info: 'param_n_estimators','mean_test_score'\" + \"-\"* 20 + '\\n')\n",
    "#report.write(str(models_cv_results10) + \"\\n\" +\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "report.write(\"-\" * 45 + '\\n')\n",
    "for target in target_scores: \n",
    "    report.write(str(target) + \"\\n\")\n",
    "#report.write(\"Overall-score: \" + str(overall_score))\n",
    "report.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try GridSeachCV on pca-ed data  (scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold  #cross_val_predict \n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "def eval_metric(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(random_state = 29 #, \n",
    "                      #n_estimators=20\n",
    "                             )\n",
    "\n",
    "\n",
    "\n",
    "cv = KFold(n_splits = 5, shuffle=True, random_state=29)\n",
    "grid_params = {\n",
    "    'n_estimators':[5, 10, 20] #,100\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, grid_params, n_jobs=-1, cv=cv, verbose=2, scoring='neg_mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.764955562353606\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.74704257873497\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   14.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.800539113930762\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.941972946579803\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.523295151269147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': RandomForestRegressor(n_estimators=20, random_state=29),\n",
       " 'domain1_var1': RandomForestRegressor(n_estimators=20, random_state=29),\n",
       " 'domain1_var2': RandomForestRegressor(n_estimators=20, random_state=29),\n",
       " 'domain2_var1': RandomForestRegressor(n_estimators=20, random_state=29),\n",
       " 'domain2_var2': RandomForestRegressor(n_estimators=20, random_state=29)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit\n",
    "\n",
    "best_models10 = {}\n",
    "models_cv_results10 = {}\n",
    "cv_info = ['param_n_estimators','mean_test_score']\n",
    "\n",
    "\n",
    "for col in targets:\n",
    "    gs.fit(Xpca_train, ypca_train[col])   \n",
    "    best_models10[col] = gs.best_estimator_  \n",
    "    models_cv_results10[col] = [gs.cv_results_.get(info) for info in cv_info]\n",
    "\n",
    "    print(gs.best_score_)\n",
    "\n",
    "best_models10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.06797016180464376\n",
      "domain1_var1: 0.05779629635483965\n",
      "domain1_var2: 0.05760204162047615\n",
      "domain2_var1: 0.07255068741893919\n",
      "domain2_var2: 0.07106840672618339\n",
      "Overall-score: 0.06571909916246983\n"
     ]
    }
   ],
   "source": [
    "weights = (.3, .175, .175, .175, .175)\n",
    "\n",
    "overall_score=0\n",
    "target_scores = []\n",
    "\n",
    "for col, weight in zip(targets, weights):\n",
    "    ypca_pred_train = best_models10[col].predict(Xpca_train)\n",
    "    score = eval_metric(ypca_train[col], ypca_pred_train)\n",
    "    overall_score += score*weight\n",
    "\n",
    "    target_scores.append((col, score))\n",
    "    print(\"{}: {}\".format(col,score))\n",
    "\n",
    "target_scores.append(('overall-score', overall_score))\n",
    "print(\"Overall-score: {}\".format(overall_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the output to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = model.__class__.__name__\n",
    "#report.write(\"---\" + model_name +  \"---\" +\"\\n\")\n",
    "\n",
    "\n",
    "report = open('gscv_pca_outfile.txt', 'w')\n",
    "\n",
    "#report.write(\"-\" * 45 + '\\n')\n",
    "report.write(\"!train feature data are pca scores from loading & fnc seperately (5pcs in each case!)\" + \"\\n\")\n",
    "report.write(\"---gridsearch: \" + \"-\"*30 + \"\\n\")\n",
    "report.write(str(gs) + \"\\n\" + \"\\n\")\n",
    "\n",
    "report.write(\"---best model params for each target :\" + \"-\"*20 +\"\\n\")\n",
    "report.write(str(best_models10) + \"\\n\" +\"\\n\")\n",
    "\n",
    "report.write(\"---model CV info: 'param_n_estimators','mean_test_score'\" + \"-\"* 20 + '\\n')\n",
    "report.write(str(models_cv_results10) + \"\\n\" +\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "report.write(\"-\" * 45 + '\\n')\n",
    "for target in target_scores: \n",
    "    report.write(str(target) + \"\\n\")\n",
    "#report.write(\"Overall-score: \" + str(overall_score))\n",
    "report.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOU CAN IGNORE THE FOLLOWING FOR NOW\n",
    "## No PCA treatment - TRAIN on raw data points\n",
    "### Split data into X_train, y_train for train data, and only X_test for test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')\n",
    "\n",
    "#prepare the train data (X_train: features; y_train: outcomes)\n",
    "X_train = train_data.drop(list(targets), axis=1).drop('Id', axis=1)\n",
    "y_train = train_data[list(targets)]\n",
    "\n",
    "# prepare the test data\n",
    "# Here, the 'fnc' features have already been 'rescaled' with a multiplication of 1/500\n",
    "Id_no = submission['Id'].apply(lambda x: int(x.split('_')[0])).unique()\n",
    "test = pd.DataFrame({'Id' : Id_no})\n",
    "test_pred_df = test.copy()\n",
    "#submission.head()\n",
    "test_data = test.merge(loading, on='Id', how='left')\n",
    "test_data = test_data.merge(fnc, on='Id', how='left')\n",
    "\n",
    "X_test = test_data.drop('Id', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV on RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GridSearchCV, KFold\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor #, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "def eval_metric(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(random_state = 29)\n",
    "#model = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "cv = KFold(n_splits = 5, shuffle=True, random_state=29)\n",
    "grid_params = {\n",
    "    'n_estimators':[5,10, 20] #,100\n",
    "}\n",
    "gs = GridSearchCV(model, grid_params, n_jobs=-1, cv=cv, verbose=2, scoring='neg_mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 16.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.472785717020276\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 19.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.630123752488837\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 27.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.698082516972553\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 23.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.8968683566741\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 23.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.446079120387248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': RandomForestRegressor(n_estimators=20, random_state=29),\n",
       " 'domain1_var1': RandomForestRegressor(n_estimators=20, random_state=29),\n",
       " 'domain1_var2': RandomForestRegressor(n_estimators=20, random_state=29),\n",
       " 'domain2_var1': RandomForestRegressor(n_estimators=20, random_state=29),\n",
       " 'domain2_var2': RandomForestRegressor(n_estimators=20, random_state=29)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_models01 = {}\n",
    "models_cv_results01 = {}\n",
    "cv_info = ['param_n_estimators','mean_test_score']\n",
    "\n",
    "\n",
    "for col in targets:\n",
    "    gs.fit(X_train, y_train[col])   \n",
    "    best_models01[col] = gs.best_estimator_  \n",
    "    models_cv_results01[col] = [gs.cv_results_.get(info) for info in cv_info]\n",
    "\n",
    "    print(gs.best_score_)\n",
    "\n",
    "best_models01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.06531893579826167\n",
      "domain1_var1: 0.0573875404435151\n",
      "domain1_var2: 0.05694669917183827\n",
      "domain2_var1: 0.07169501263787025\n",
      "domain2_var2: 0.06906957637857804\n",
      "Overall-score: 0.06575444676198482\n"
     ]
    }
   ],
   "source": [
    "weights = (.3, .175, .175, .175, .175)\n",
    "\n",
    "overall_score01=0\n",
    "target_scores01 = []\n",
    "\n",
    "for col, weight in zip(targets, weights):\n",
    "    y_pred_train = best_models01[col].predict(X_train)\n",
    "    score = eval_metric(y_train[col], y_pred_train)\n",
    "    overall_score01 += score*weight\n",
    "\n",
    "    target_scores01.append((col, score))\n",
    "    print(\"{}: {}\".format(col,score))\n",
    "\n",
    "target_scores01.append(('overall-score', overall_score))\n",
    "print(\"Overall-score: {}\".format(overall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More model testing will be incorporated here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics to assess the performances of the models for this challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(y_true, y_pred):\n",
    "    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict  #GridSearchCV, KFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5\n",
    ")\n",
    "\n",
    "\n",
    "#cv = KFold(n_splits = 5, shuffle=True, random_state=29)\n",
    "#grid = {\n",
    "#    'n_estimators':[5,10]  #20,100\n",
    "#}\n",
    "#gs = GridSearchCV(model, grid, n_jobs=-1, cv=cv, verbose=5, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#best_models = {}\n",
    "#for col in features:\n",
    "#    gs.fit(X_train, y_train[col])   \n",
    "#    best_models[col] = gs.best_estimator_  \n",
    "#    print(gs.best_score_)\n",
    "#\n",
    "#best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "targets = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (.3, .175, .175, .175, .175)\n",
    "overall_score=0\n",
    "\n",
    "\n",
    "for col, weight in zip(targets, weights): \n",
    "    y_pred_train = cross_val_predict(model, X_train, y_train[col], cv=3, n_jobs=-1, verbose=10)\n",
    "    \n",
    "    #print(y_pred_train)\n",
    "    \n",
    "    score = eval_metric(y_train[col], y_pred_train)\n",
    "    overall_score += score*weight\n",
    "    \n",
    "    print(\"{}: {}\".format(col,score))\n",
    "print(\"Overall-score: {}\".format(overall_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#weights = (.3, .175, .175, .175, .175)\n",
    "#\n",
    "#overall_score=0\n",
    "#\n",
    "#for col, weight in zip(features, weights):\n",
    "#    y_pred_train = best_models[col].predict(X_train)\n",
    "#    score = eval_metric(y_train[col], y_pred_train)\n",
    "#    overall_score += score*weight\n",
    "#\n",
    "#    print(\"{}: {}\".format(col,score))\n",
    "#print(\"Overall-score: {}\".format(overall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore them from now...\n",
    "### Preparing the 'test' predicted outcomes in the format required for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in targets:\n",
    "    test_pred_df[col] = best_models[col].predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.melt(test_pred_df, id_vars=[\"Id\"], value_name='Predicted')\n",
    "submit_df[\"Id\"]=submit_df[\"Id\"].astype(\"str\") + \"_\" + submit_df[\"variable\"].astype(\"str\")\n",
    "\n",
    "submit_df = submit_df.drop(\"variable\", axis=1).sort_values(\"Id\")\n",
    "\n",
    "#check if the submit_df has the correct number of entries\n",
    "if not submit_df.shape[0] == test_pred_df.shape[0]*5:\n",
    "    raise AssertionError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
